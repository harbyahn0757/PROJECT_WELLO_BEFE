import asyncio
import json
import os
import sys
from datetime import datetime
from unittest.mock import MagicMock, patch
from dotenv import load_dotenv

# 1. Load Environment Variables
backend_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "../planning-platform/backend"))
config_path = os.path.join(backend_path, "config.env")
load_dotenv(config_path)

# Verify API Keys
if not os.getenv("GOOGLE_GEMINI_API_KEY") and not os.getenv("OPENAI_API_KEY"):
    print("âŒ Error: API Keys not found in config.env")
    sys.exit(1)

# Add backend root to sys.path
sys.path.append(backend_path)

# Import Backend Modules
from app.api.v1.endpoints.checkup_design import CheckupDesignRequest, CheckupDesignStep2Request, Step1Result
from app.services.checkup_design.step1_prompt import create_step1_prompt

# Mock Data (DB Bypass)
MOCK_HOSPITAL_INFO = {
    "hospital_name": "í…ŒìŠ¤íŠ¸ ë³‘ì› (Real LLM Test)",
    "national_checkup_items": [
        {"name": "ì‹ ì²´ê³„ì¸¡", "category": "ê¸°ì´ˆ"},
        {"name": "í˜ˆì••ì¸¡ì •", "category": "ê¸°ì´ˆ"},
        {"name": "í‰ë¶€ë°©ì‚¬ì„ ì´¬ì˜", "category": "ì˜ìƒì˜í•™"},
        {"name": "ìš”ê²€ì‚¬", "category": "ì§„ë‹¨ê²€ì‚¬"},
        {"name": "í˜ˆì•¡ê²€ì‚¬", "category": "ì§„ë‹¨ê²€ì‚¬"},
        {"name": "êµ¬ê°•ê²€ì§„", "category": "ì¹˜ê³¼"}
    ],
    "recommended_items": [
        {"name": "ìœ„ ë‚´ì‹œê²½", "category": "ì†Œí™”ê¸°", "description": "ìœ„ì•” ì¡°ê¸° ë°œê²¬"},
        {"name": "ëŒ€ì¥ ë‚´ì‹œê²½", "category": "ì†Œí™”ê¸°", "description": "ëŒ€ì¥ì•” ë° ìš©ì¢… ë°œê²¬"},
        {"name": "ë³µë¶€ ì´ˆìŒíŒŒ", "category": "ì†Œí™”ê¸°", "description": "ê°„/ë‹´ë‚­/ì·Œì¥ í™•ì¸"},
        {"name": "ì €ì„ ëŸ‰ í CT", "category": "í˜¸í¡ê¸°", "description": "íì•” ì¡°ê¸° ë°œê²¬"},
        {"name": "ë‡Œ MRA", "category": "ë‡Œì‹ ê²½", "description": "ë‡Œí˜ˆê´€ ìƒíƒœ í™•ì¸"},
        {"name": "ê²½ë™ë§¥ ì´ˆìŒíŒŒ", "category": "ì‹¬í˜ˆê´€", "description": "ë™ë§¥ê²½í™”ë„ ì¸¡ì •"},
        {"name": "ê´€ìƒë™ë§¥ ì„íšŒí™” CT", "category": "ì‹¬í˜ˆê´€", "description": "ì‹¬ì¥ í˜ˆê´€ ì„íšŒí™” í™•ì¸"},
        {"name": "ê°‘ìƒì„  ì´ˆìŒíŒŒ", "category": "ë‚´ë¶„ë¹„", "description": "ê°‘ìƒì„  ê²°ì ˆ/ì•” í™•ì¸"}
    ],
    "external_checkup_items": [
        {"name": "NKì„¸í¬ í™œì„±ë„ ê²€ì‚¬", "category": "ë©´ì—­", "description": "ë©´ì—­ë ¥ ì¸¡ì •"},
        {"name": "ë§ˆìŠ¤íŠ¸ ì•Œë ˆë¥´ê¸° ê²€ì‚¬", "category": "ë©´ì—­", "description": "ì•Œë ˆë¥´ê¸° ì›ì¸ ê·œëª…"},
        {"name": "ìœ ì „ì ê²€ì‚¬ (DTC)", "category": "ìœ ì „ì", "description": "íƒ€ê³ ë‚œ ìœ ì „ì  íŠ¹ì„± íŒŒì•…"}
    ]
}

async def run_real_test_case(idx, case_data):
    print(f"\n[{idx+1}] ğŸ§ª Testing Case (Real LLM): {case_data['patient_name']} ({case_data['case_description']})")
    
    # Request Data Setup
    request_data = {
        "uuid": case_data['uuid'],
        "hospital_id": case_data['hospital_id'],
        "selected_concerns": case_data.get('selected_concerns', []),
        "survey_responses": case_data.get('survey_responses', {}),
        "additional_info": {},
        "events": case_data.get('user_attributes', [])
    }
    
    # Mock Only Data Service (DB Access)
    with patch("app.services.wello_data_service.WelloDataService.get_patient_by_uuid") as mock_get_patient, \
         patch("app.services.wello_data_service.WelloDataService.get_hospital_by_id") as mock_get_hospital, \
         patch("app.services.wello_data_service.WelloDataService.get_patient_health_data") as mock_get_health, \
         patch("app.services.wello_data_service.WelloDataService.get_patient_prescription_data") as mock_get_presc, \
         patch("app.services.wello_data_service.WelloDataService.save_checkup_design_request") as mock_save:

        # Setup Mock Returns
        mock_get_patient.return_value = {
            "name": case_data['patient_name'],
            "birth_date": f"{datetime.now().year - case_data['age']}-01-01T00:00:00Z",
            "gender": case_data['gender']
        }
        mock_get_hospital.return_value = MOCK_HOSPITAL_INFO
        mock_get_health.return_value = {"health_data": case_data.get('health_history', [])}
        mock_get_presc.return_value = {"prescription_data": []}
        mock_save.return_value = {"success": True, "request_id": f"real_test_{idx}"}

        # ------------------------------------------------------------------
        # STEP 1: Analysis (Actual LLM Call)
        # ------------------------------------------------------------------
        from app.api.v1.endpoints.checkup_design import create_checkup_design_step1
        
        step1_result = {}
        try:
            print("   â³ Step 1 Analyzing (Calling Gemini)...")
            req_model = CheckupDesignRequest(**request_data)
            step1_response = await create_checkup_design_step1(req_model)
            step1_result = step1_response.data
            
            # Log Result
            persona = step1_result.get("persona", {})
            print(f"   âœ… [Step 1] Persona: {persona.get('primary_persona')} (Score: {persona.get('persona_score', {}).get(persona.get('primary_persona', ''))})")
            print(f"   âœ… [Step 1] Combined: {persona.get('combined_type')}")
            print(f"   âœ… [Step 1] Risk Flags: {persona.get('risk_flags')}")

        except Exception as e:
            print(f"   âŒ Step 1 Failed: {str(e)}")
            import traceback
            traceback.print_exc()
            return

        # ------------------------------------------------------------------
        # STEP 2: Design (Actual LLM Call)
        # ------------------------------------------------------------------
        from app.api.v1.endpoints.checkup_design import create_checkup_design_step2
        
        try:
            print("   â³ Step 2 Designing (Calling Gemini/GPT)...")
            step2_req_model = CheckupDesignStep2Request(
                uuid=request_data['uuid'],
                hospital_id=request_data['hospital_id'],
                step1_result=Step1Result(**step1_result),
                selected_concerns=req_model.selected_concerns,
                survey_responses=req_model.survey_responses
            )
            
            step2_response = await create_checkup_design_step2(step2_req_model)
            final_result = step2_response.data
            
            # Save Result
            output_dir = "tests/integration_data/results"
            os.makedirs(output_dir, exist_ok=True)
            output_file = f"{output_dir}/result_{idx+1}_{case_data['patient_name']}.json"
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(final_result, f, indent=2, ensure_ascii=False)
            
            # Validation Check
            priority_2 = final_result.get('priority_2', {}).get('items', [])
            print(f"   âœ… [Step 2] Recommended: {priority_2}")
            print(f"   ğŸ’¾ Saved to {output_file}")
            
        except Exception as e:
            print(f"   âŒ Step 2 Failed: {str(e)}")
            import traceback
            traceback.print_exc()

async def main():
    # Load Dataset
    try:
        with open('tests/integration_data/qa_dataset.json', 'r', encoding='utf-8') as f:
            dataset = json.load(f)
    except FileNotFoundError:
        print("âŒ qa_dataset.json not found. Run generate_test_dataset.py first.")
        return
    
    print(f"ğŸš€ Starting Real Integration Test for {len(dataset)} cases...")
    print("âš ï¸  Warning: This will consume API credits.")
    
    # Run only first 5 cases (Edge Cases) to save time/cost, unless user wants all
    # User said "20ê°œ ì •ë„", so we run all.
    for i, case in enumerate(dataset):
        await run_real_test_case(i, case)
        
    print("\nâœ… All Real Tests Completed.")

if __name__ == "__main__":
    asyncio.run(main())


