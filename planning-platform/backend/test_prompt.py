"""
í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê¸°ì¡´ ì‹œìŠ¤í…œì˜ GPT ì„œë¹„ìŠ¤ì™€ ì„¤ì •ì„ ì¬ì‚¬ìš©í•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""
import asyncio
import json
import sys
import os
from pathlib import Path
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.services.gpt_service import GPTService, GPTRequest
from app.services.session_logger import get_session_logger
from app.core.config import settings

# RAG ì‹œìŠ¤í…œ ì„í¬íŠ¸
try:
    from app.services.checkup_design import (
        init_rag_engine,
        generate_specific_queries,
        get_medical_evidence_from_rag
    )
    RAG_AVAILABLE = True
except ImportError:
    RAG_AVAILABLE = False
    print("[WARN] RAG ì‹œìŠ¤í…œì„ ì„í¬íŠ¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


class PromptTester:
    """í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.gpt_service = GPTService()
        self.session_logger = get_session_logger()
        self.rag_engine = None
        
    async def test_prompt(
        self,
        system_message: str,
        user_message: str,
        model: str = "gpt-4o-mini",
        temperature: float = 0.5,
        max_tokens: int = 2000,
        json_mode: bool = False,
        save_log: bool = True,
        patient_uuid: str = "test_user",
        session_id: str = None
    ):
        """
        í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        
        Args:
            system_message: ì‹œìŠ¤í…œ ë©”ì‹œì§€
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€ (í”„ë¡¬í”„íŠ¸)
            model: GPT ëª¨ë¸ (ê¸°ë³¸: gpt-4o-mini)
            temperature: ì˜¨ë„ (0.0-1.0)
            max_tokens: ìµœëŒ€ í† í° ìˆ˜
            json_mode: JSON ì‘ë‹µ ëª¨ë“œ ì‚¬ìš© ì—¬ë¶€
            save_log: ë¡œê·¸ ì €ì¥ ì—¬ë¶€
            patient_uuid: í™˜ì UUID (ë¡œê¹…ìš©)
            session_id: ì„¸ì…˜ ID (ì—†ìœ¼ë©´ ìë™ ìƒì„±)
        """
        print("\n" + "="*80)
        print("ğŸ§ª í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("="*80)
        
        # GPT ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
        await self.gpt_service.initialize()
        
        # ì„¸ì…˜ ID ìƒì„± (ì œê³µë˜ì§€ ì•Šì€ ê²½ìš°)
        if not session_id:
            session_id = self.session_logger.start_session(
                patient_uuid=patient_uuid,
                patient_name="í…ŒìŠ¤íŠ¸ í™˜ì",
                hospital_id="test_hospital"
            )
            print(f"ğŸ¬ ì„¸ì…˜ ID ìƒì„±: {session_id}")
        
        # ìš”ì²­ ì •ë³´ ì¶œë ¥
        print(f"\nğŸ“‹ ìš”ì²­ ì •ë³´:")
        print(f"  - ëª¨ë¸: {model}")
        print(f"  - ì˜¨ë„: {temperature}")
        print(f"  - ìµœëŒ€ í† í°: {max_tokens}")
        print(f"  - JSON ëª¨ë“œ: {json_mode}")
        print(f"  - ë¡œê·¸ ì €ì¥: {save_log}")
        print(f"\nğŸ“ ì‹œìŠ¤í…œ ë©”ì‹œì§€ ê¸¸ì´: {len(system_message)} ì")
        print(f"ğŸ“ ì‚¬ìš©ì ë©”ì‹œì§€ ê¸¸ì´: {len(user_message)} ì")
        
        # í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°
        print(f"\n{'â”€'*80}")
        print("ğŸ” ì‹œìŠ¤í…œ ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):")
        print(f"{'â”€'*80}")
        print(system_message[:500] + "..." if len(system_message) > 500 else system_message)
        
        print(f"\n{'â”€'*80}")
        print("ğŸ” ì‚¬ìš©ì ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 500ì):")
        print(f"{'â”€'*80}")
        print(user_message[:500] + "..." if len(user_message) > 500 else user_message)
        
        # GPT ìš”ì²­ ìƒì„±
        gpt_request = GPTRequest(
            system_message=system_message,
            user_message=user_message,
            model=model,
            temperature=temperature,
            max_tokens=max_tokens,
            response_format={"type": "json_object"} if json_mode else None
        )
        
        # API í˜¸ì¶œ
        print(f"\n{'â”€'*80}")
        print("ğŸš€ GPT API í˜¸ì¶œ ì¤‘...")
        print(f"{'â”€'*80}")
        
        start_time = datetime.now()
        
        try:
            response = await self.gpt_service.call_api(
                request=gpt_request,
                save_log=save_log,
                patient_uuid=patient_uuid,
                session_id=session_id,
                step_number="TEST",
                step_name="í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"
            )
            
            elapsed_time = (datetime.now() - start_time).total_seconds()
            
            if response.success:
                print(f"\nâœ… API í˜¸ì¶œ ì„±ê³µ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
                print(f"\n{'â”€'*80}")
                print("ğŸ“Š ì‘ë‹µ ì •ë³´:")
                print(f"{'â”€'*80}")
                print(f"  - ëª¨ë¸: {response.model}")
                print(f"  - í”„ë¡¬í”„íŠ¸ í† í°: {response.usage.get('prompt_tokens', 0):,}")
                print(f"  - ì™„ë£Œ í† í°: {response.usage.get('completion_tokens', 0):,}")
                print(f"  - ì´ í† í°: {response.usage.get('total_tokens', 0):,}")
                
                print(f"\n{'='*80}")
                print("ğŸ’¬ GPT ì‘ë‹µ:")
                print(f"{'='*80}")
                
                # JSON ëª¨ë“œì¸ ê²½ìš° í¬ë§·íŒ…
                if json_mode:
                    try:
                        parsed = json.loads(response.content)
                        print(json.dumps(parsed, ensure_ascii=False, indent=2))
                    except json.JSONDecodeError:
                        print(response.content)
                else:
                    print(response.content)
                
                print(f"\n{'='*80}")
                
                # ë¡œê·¸ ì €ì¥ ìœ„ì¹˜ ì•ˆë‚´
                if save_log:
                    log_path = f"logs/patient_{patient_uuid[:8]}.json"
                    print(f"\nğŸ’¾ ë¡œê·¸ ì €ì¥ë¨: {log_path}")
                    print(f"   ì„¸ì…˜ ID: {session_id}")
                
                return {
                    "success": True,
                    "response": response.content,
                    "usage": response.usage,
                    "elapsed_time": elapsed_time,
                    "session_id": session_id
                }
                
            else:
                print(f"\nâŒ API í˜¸ì¶œ ì‹¤íŒ¨")
                print(f"ì—ëŸ¬: {response.error}")
                return {
                    "success": False,
                    "error": response.error,
                    "session_id": session_id
                }
                
        except Exception as e:
            elapsed_time = (datetime.now() - start_time).total_seconds()
            print(f"\nâŒ ì˜ˆì™¸ ë°œìƒ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
            print(f"ì—ëŸ¬: {str(e)}")
            import traceback
            traceback.print_exc()
            return {
                "success": False,
                "error": str(e),
                "session_id": session_id
            }


async def test_simple_prompt():
    """ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ"""
    tester = PromptTester()
    
    system_message = """ë‹¹ì‹ ì€ ê±´ê°• ê²€ì§„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
í™˜ìì˜ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ê²€ì§„ í•­ëª©ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”."""
    
    user_message = """
í™˜ì ì •ë³´:
- ë‚˜ì´: 45ì„¸
- ì„±ë³„: ë‚¨ì„±
- ê³¼ê±° ê²€ì§„: í˜ˆì•• ê²½ê³„, í˜ˆë‹¹ ì •ìƒ
- ê°€ì¡±ë ¥: ë‹¹ë‡¨, ê³ í˜ˆì••

ìœ„ í™˜ìì—ê²Œ ì¶”ì²œí•  ê²€ì§„ í•­ëª© 3ê°€ì§€ë¥¼ ì„¤ëª…ê³¼ í•¨ê»˜ ì•Œë ¤ì£¼ì„¸ìš”.
"""
    
    result = await tester.test_prompt(
        system_message=system_message,
        user_message=user_message,
        model="gpt-4o-mini",
        temperature=0.7,
        max_tokens=1000,
        json_mode=False,
        save_log=True
    )
    
    return result


async def test_json_response():
    """JSON ì‘ë‹µ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ"""
    tester = PromptTester()
    
    system_message = """ë‹¹ì‹ ì€ ê±´ê°• ê²€ì§„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”."""
    
    user_message = """
í™˜ì ì •ë³´:
- ë‚˜ì´: 45ì„¸
- ì„±ë³„: ë‚¨ì„±
- ê³¼ê±° ê²€ì§„: í˜ˆì•• ê²½ê³„
- ê°€ì¡±ë ¥: ë‹¹ë‡¨

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "recommended_items": [
    {
      "name": "ê²€ì§„ í•­ëª©ëª…",
      "reason": "ì¶”ì²œ ì´ìœ ",
      "priority": 1-3
    }
  ],
  "summary": "ì¢…í•© ì˜ê²¬"
}
"""
    
    result = await tester.test_prompt(
        system_message=system_message,
        user_message=user_message,
        model="gpt-4o",
        temperature=0.5,
        max_tokens=2000,
        json_mode=True,
        save_log=True
    )
    
    return result


async def test_custom_prompt(system_msg: str, user_msg: str, **kwargs):
    """ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸"""
    tester = PromptTester()
    
    result = await tester.test_prompt(
        system_message=system_msg,
        user_message=user_msg,
        **kwargs
    )
    
    return result


async def test_rag_search():
    """RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ"""
    if not RAG_AVAILABLE:
        print("âŒ RAG ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {"success": False, "error": "RAG not available"}
    
    print("\n" + "="*80)
    print("ğŸ” RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("="*80)
    
    try:
        # RAG ì—”ì§„ ì´ˆê¸°í™”
        print("\nğŸš€ RAG ì—”ì§„ ì´ˆê¸°í™” ì¤‘...")
        query_engine = await init_rag_engine()
        
        if not query_engine:
            print("âŒ RAG ì—”ì§„ ì´ˆê¸°í™” ì‹¤íŒ¨")
            return {"success": False, "error": "RAG engine initialization failed"}
        
        print("âœ… RAG ì—”ì§„ ì´ˆê¸°í™” ì„±ê³µ")
        
        # í™˜ì ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
        patient_context = {
            "age": 45,
            "gender": "male",
            "family_history": ["diabetes", "hypertension"],
            "abnormal_items": ["í˜ˆì•• ê²½ê³„", "í˜ˆë‹¹ ê²½ê³„"]
        }
        
        # ì—¼ë ¤ í•­ëª©
        concerns = [
            {"type": "checkup", "name": "í˜ˆì••", "value": "135", "status": "ê²½ê³„"},
            {"type": "checkup", "name": "í˜ˆë‹¹", "value": "110", "status": "ê²½ê³„"}
        ]
        
        print("\nğŸ“‹ ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸:")
        print(f"  - ë‚˜ì´: {patient_context['age']}ì„¸")
        print(f"  - ì„±ë³„: {'ë‚¨ì„±' if patient_context['gender'] == 'male' else 'ì—¬ì„±'}")
        print(f"  - ê°€ì¡±ë ¥: {', '.join(patient_context['family_history'])}")
        print(f"  - ì—¼ë ¤ í•­ëª©: {len(concerns)}ê°œ")
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        print("\nğŸ” ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì¤‘...")
        queries = generate_specific_queries(patient_context, concerns)
        print(f"âœ… {len(queries)}ê°œ ì¿¼ë¦¬ ìƒì„±ë¨")
        
        for i, q in enumerate(queries[:3], 1):  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
            print(f"  {i}. [{q['category']}] {q['query']}")
        
        # RAG ê²€ìƒ‰ ì‹¤í–‰
        print("\nğŸš€ RAG ê²€ìƒ‰ ì‹¤í–‰ ì¤‘...")
        start_time = datetime.now()
        
        rag_result = await get_medical_evidence_from_rag(
            query_engine=query_engine,
            patient_context=patient_context,
            concerns=concerns
        )
        
        elapsed_time = (datetime.now() - start_time).total_seconds()
        
        context_text = rag_result.get("context_text", "")
        structured_evidences = rag_result.get("structured_evidences", [])
        
        print(f"\nâœ… RAG ê²€ìƒ‰ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ)")
        print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼:")
        print(f"  - ì—ë¹„ë˜ìŠ¤ ê°œìˆ˜: {len(structured_evidences)}ê°œ")
        print(f"  - ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(context_text):,}ì")
        
        if structured_evidences:
            print(f"\nğŸ“š ì—ë¹„ë˜ìŠ¤ ë¯¸ë¦¬ë³´ê¸°:")
            for i, ev in enumerate(structured_evidences[:3], 1):
                print(f"\n  [{i}] ì¹´í…Œê³ ë¦¬: {ev.get('category', 'N/A')}")
                print(f"      ë¬¸ì„œ: {ev.get('document_name', 'N/A')}")
                citation = ev.get('citation', '')
                preview = citation[:150] + "..." if len(citation) > 150 else citation
                print(f"      ì¸ìš©: {preview}")
        
        if context_text:
            print(f"\n{'='*80}")
            print("ğŸ’¬ ì „ì²´ ì»¨í…ìŠ¤íŠ¸ (ì²˜ìŒ 1000ì):")
            print(f"{'='*80}")
            print(context_text[:1000] + "..." if len(context_text) > 1000 else context_text)
        
        return {
            "success": True,
            "evidence_count": len(structured_evidences),
            "context_length": len(context_text),
            "elapsed_time": elapsed_time,
            "evidences": structured_evidences
        }
        
    except Exception as e:
        print(f"\nâŒ RAG ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()
        return {"success": False, "error": str(e)}


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "="*80)
    print("ğŸ§ª í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ë„êµ¬")
    print("="*80)
    print("\nì‚¬ìš© ê°€ëŠ¥í•œ í…ŒìŠ¤íŠ¸:")
    print("  1. ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ (test_simple_prompt)")
    print("  2. JSON ì‘ë‹µ í…ŒìŠ¤íŠ¸ (test_json_response)")
    print("  3. RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ (test_rag_search)")
    print("  4. ì»¤ìŠ¤í…€ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ (test_custom_prompt)")
    print("\ní™˜ê²½ ë³€ìˆ˜:")
    print(f"  - OpenAI API Key: {'ì„¤ì •ë¨' if settings.openai_api_key and not settings.openai_api_key.startswith('sk-proj-your-') else 'ë¯¸ì„¤ì •'}")
    print(f"  - ê¸°ë³¸ ëª¨ë¸: {getattr(settings, 'openai_model', 'gpt-4o-mini')}")
    print(f"  - RAG ì‹œìŠ¤í…œ: {'ì‚¬ìš© ê°€ëŠ¥' if RAG_AVAILABLE else 'ì‚¬ìš© ë¶ˆê°€'}")
    if RAG_AVAILABLE:
        llamaindex_key = getattr(settings, 'llamaindex_api_key', None)
        gemini_key = getattr(settings, 'google_gemini_api_key', None)
        print(f"    * LlamaIndex API Key: {'ì„¤ì •ë¨' if llamaindex_key and not llamaindex_key.startswith('dev-') else 'ë¯¸ì„¤ì •'}")
        print(f"    * Gemini API Key: {'ì„¤ì •ë¨' if gemini_key and not gemini_key.startswith('dev-') else 'ë¯¸ì„¤ì •'}")
    print("\n" + "="*80)
    
    # ì˜ˆì‹œ 1: ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    print("\nğŸ”¹ ì˜ˆì‹œ 1: ê°„ë‹¨í•œ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    asyncio.run(test_simple_prompt())
    
    # ì˜ˆì‹œ 2: JSON ì‘ë‹µ í…ŒìŠ¤íŠ¸
    # print("\nğŸ”¹ ì˜ˆì‹œ 2: JSON ì‘ë‹µ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    # asyncio.run(test_json_response())
    
    # ì˜ˆì‹œ 3: RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    # print("\nğŸ”¹ ì˜ˆì‹œ 3: RAG ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    # asyncio.run(test_rag_search())


if __name__ == "__main__":
    main()

