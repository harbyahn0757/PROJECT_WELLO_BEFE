"""
ì±„íŒ… ì„¸ì…˜ ìë™ íƒœê¹… ì„œë¹„ìŠ¤

ëŒ€í™” ì™„ë£Œ í›„ ë¹„ë™ê¸°ë¡œ í˜¸ì¶œë˜ì–´ interest_tags, risk_tags, sentiment ë“±ì„ ìë™ ë¶„ì„í•˜ê³  DBì— ì €ì¥í•©ë‹ˆë‹¤.
"""

import logging
import json
from typing import Dict, Any, Optional, List
from datetime import datetime

from ..core.database import db_manager

logger = logging.getLogger(__name__)


# ê´€ì‹¬ì‚¬ í‚¤ì›Œë“œ ì‚¬ì „
INTEREST_KEYWORDS: Dict[str, List[str]] = {
    "ë‹¤ì´ì–´íŠ¸": ["ë‹¤ì´ì–´íŠ¸", "ì‚´", "ì²´ì¤‘", "ë¹„ë§Œ", "BMI", "ê°ëŸ‰"],
    "í˜ˆì••": ["í˜ˆì••", "ê³ í˜ˆì••", "ì €í˜ˆì••", "ìˆ˜ì¶•ê¸°", "ì´ì™„ê¸°"],
    "ë‹¹ë‡¨": ["ë‹¹ë‡¨", "í˜ˆë‹¹", "ê³µë³µí˜ˆë‹¹", "ì¸ìŠë¦°", "HbA1c"],
    "ê°„ê¸°ëŠ¥": ["ê°„", "AST", "ALT", "ê°ë§ˆ", "GGT", "ì§€ë°©ê°„"],
    "ì½œë ˆìŠ¤í…Œë¡¤": ["ì½œë ˆìŠ¤í…Œë¡¤", "ì¤‘ì„±ì§€ë°©", "HDL", "LDL", "ì´ìƒì§€ì§ˆ"],
    "ì‹ ì¥": ["ì‹ ì¥", "í¬ë ˆì•„í‹°ë‹Œ", "ì‚¬êµ¬ì²´", "GFR", "ì½©íŒ¥"],
    "ì•”": ["ì•”", "ì¢…ì–‘", "ìš©ì¢…", "ì¡°ì§ê²€ì‚¬"],
    "ìœ„ì¥": ["ìœ„", "ìœ„ë‚´ì‹œê²½", "ìœ„ì•”", "í—¬ë¦¬ì½”ë°•í„°", "ì—­ë¥˜"],
    "ê°‘ìƒì„ ": ["ê°‘ìƒì„ ", "TSH", "T3", "T4"],
    "ë¹ˆí˜ˆ": ["ë¹ˆí˜ˆ", "í˜ˆìƒ‰ì†Œ", "í—¤ëª¨ê¸€ë¡œë¹ˆ", "ì² ë¶„"],
    "ì‹¬ì¥": ["ì‹¬ì¥", "ì‹¬ì „ë„", "ë¶€ì •ë§¥", "í˜‘ì‹¬ì¦"],
    "í": ["í", "í‰ë¶€", "X-ray", "ê²°í•µ"],
}

# ê°ì • í‚¤ì›Œë“œ ì‚¬ì „
SENTIMENT_KEYWORDS: Dict[str, List[str]] = {
    "positive": ["ê°ì‚¬", "ê³ ë§ˆì›Œ", "ì¢‹ì•„", "ì¢‹ê² ", "ë„ì›€", "ì´í•´", "ì•Œê² ", "ê³ ë§™"],
    "negative": ["ì‹«", "ì•„ë‹Œë°", "í‹€ë ¸", "ì´ìƒí•´", "ë¶ˆë§Œ", "í™”ë‚˜", "ì§œì¦", "ê±±ì •"],
    "confused": ["ëª¨ë¥´ê² ", "ì–´ë µ", "ë³µì¡", "ì´í•´ê°€ ì•ˆ", "ë¬´ìŠ¨ ë§", "ë­”ì†Œë¦¬"],
}

# ê²€ì§„ ë°ì´í„° í’ˆì§ˆ í‰ê°€ìš© í•„ìˆ˜ í•„ë“œ
QUALITY_REQUIRED_FIELDS = [
    "height", "weight", "bmi",
    "systolic_bp", "diastolic_bp",
    "fasting_glucose",
    "total_cholesterol", "hdl_cholesterol", "ldl_cholesterol",
    "hemoglobin", "sgot_ast", "sgpt_alt", "gamma_gtp",
    "creatinine", "gfr",
]


def extract_interest_tags(messages: List[Dict[str, str]]) -> List[str]:
    """ì‚¬ìš©ì ë©”ì‹œì§€ì—ì„œ ê´€ì‹¬ì‚¬ íƒœê·¸ ì¶”ì¶œ"""
    user_text = " ".join(
        m.get("content", "") for m in messages if m.get("role") == "user"
    )
    tags = []
    for tag, keywords in INTEREST_KEYWORDS.items():
        if any(kw in user_text for kw in keywords):
            tags.append(tag)
    return tags


def extract_risk_tags(health_metrics: Dict[str, Any]) -> List[str]:
    """health_metricsì˜ *_abnormal í•„ë“œì—ì„œ ë¹„ì •ìƒ í•­ëª© ì¶”ì¶œ"""
    risks = []
    if not health_metrics:
        return risks
    for key, val in health_metrics.items():
        if key.endswith("_abnormal") and val and val != "ì •ìƒ":
            metric_name = key.replace("_abnormal", "")
            risks.append(f"{metric_name}_{val}")
    return risks


def extract_keyword_tags(messages: List[Dict[str, str]]) -> List[str]:
    """ëŒ€í™”ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ íƒœê·¸ ì¶”ì¶œ (ëª¨ë“  interest í‚¤ì›Œë“œì˜ ë§¤ì¹­ ê²°ê³¼)"""
    all_text = " ".join(m.get("content", "") for m in messages)
    matched = set()
    for keywords in INTEREST_KEYWORDS.values():
        for kw in keywords:
            if kw in all_text:
                matched.add(kw)
    return list(matched)[:20]  # ìµœëŒ€ 20ê°œ


def detect_sentiment(messages: List[Dict[str, str]]) -> str:
    """ì‚¬ìš©ì ë§ˆì§€ë§‰ ë©”ì‹œì§€ ê¸°ë°˜ ê°ì • íŒë³„"""
    user_messages = [m for m in messages if m.get("role") == "user"]
    if not user_messages:
        return "neutral"
    last_msg = user_messages[-1].get("content", "")

    for sentiment, keywords in SENTIMENT_KEYWORDS.items():
        if any(kw in last_msg for kw in keywords):
            return sentiment
    return "neutral"


def calculate_data_quality_score(health_metrics: Dict[str, Any]) -> int:
    """ê²€ì§„ ë°ì´í„° ì™„ì„±ë„ ì ìˆ˜ (0-100)"""
    if not health_metrics:
        return 0
    valid_count = 0
    for field in QUALITY_REQUIRED_FIELDS:
        val = health_metrics.get(field)
        if val is not None and val != 0 and val != "" and val != "0":
            valid_count += 1
    return int((valid_count / len(QUALITY_REQUIRED_FIELDS)) * 100)


async def generate_conversation_summary(messages: List[Dict[str, str]]) -> str:
    """ëŒ€í™” ë‚´ìš©ì„ 1-2ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ (ê°„ì´ ë²„ì „ â€” LLM ì—†ì´ ê·œì¹™ ê¸°ë°˜)"""
    user_messages = [m.get("content", "") for m in messages if m.get("role") == "user"]
    if not user_messages:
        return ""
    # ì²« ì§ˆë¬¸ + ë§ˆì§€ë§‰ ì§ˆë¬¸ì„ ì¡°í•©
    first_q = user_messages[0][:60]
    if len(user_messages) > 1:
        last_q = user_messages[-1][:60]
        return f"ì²« ì§ˆë¬¸: {first_q} / ë§ˆì§€ë§‰ ì§ˆë¬¸: {last_q} (ì´ {len(user_messages)}íšŒ ì§ˆë¬¸)"
    return f"ì§ˆë¬¸: {first_q}"


async def tag_chat_session(
    session_id: str,
    partner_id: str,
    messages: List[Dict[str, str]],
    health_metrics: Optional[Dict[str, Any]] = None,
    has_discrepancy: bool = False,
) -> Optional[Dict[str, Any]]:
    """
    ëŒ€í™” ì„¸ì…˜ì— ëŒ€í•œ ìë™ íƒœê¹… ìˆ˜í–‰ ë° DB ì €ì¥

    Args:
        session_id: ì„¸ì…˜ ID
        partner_id: íŒŒíŠ¸ë„ˆ ID
        messages: ëŒ€í™” ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ [{"role": "user"|"assistant", "content": "..."}]
        health_metrics: ê²€ì§„ ë°ì´í„° (ìˆëŠ” ê²½ìš°)
        has_discrepancy: CLIENT_RAG_DISCREPANCY ë°œìƒ ì—¬ë¶€

    Returns:
        ì €ì¥ëœ íƒœê·¸ ë°ì´í„° ë˜ëŠ” None
    """
    try:
        interest_tags = extract_interest_tags(messages)
        risk_tags = extract_risk_tags(health_metrics or {})
        keyword_tags = extract_keyword_tags(messages)
        sentiment = detect_sentiment(messages)
        data_quality = calculate_data_quality_score(health_metrics or {})
        summary = await generate_conversation_summary(messages)

        tag_data = {
            "session_id": session_id,
            "partner_id": partner_id,
            "interest_tags": interest_tags,
            "risk_tags": risk_tags,
            "keyword_tags": keyword_tags,
            "sentiment": sentiment,
            "conversation_summary": summary,
            "data_quality_score": data_quality,
            "has_discrepancy": has_discrepancy,
        }

        # DB ì €ì¥ (Upsert)
        upsert_query = """
            INSERT INTO welno.tb_chat_session_tags
            (session_id, partner_id, interest_tags, risk_tags, keyword_tags,
             sentiment, conversation_summary, data_quality_score, has_discrepancy)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (session_id, partner_id) DO UPDATE SET
                interest_tags = EXCLUDED.interest_tags,
                risk_tags = EXCLUDED.risk_tags,
                keyword_tags = EXCLUDED.keyword_tags,
                sentiment = EXCLUDED.sentiment,
                conversation_summary = EXCLUDED.conversation_summary,
                data_quality_score = EXCLUDED.data_quality_score,
                has_discrepancy = EXCLUDED.has_discrepancy,
                updated_at = NOW()
        """
        await db_manager.execute_update(upsert_query, (
            session_id,
            partner_id,
            json.dumps(interest_tags, ensure_ascii=False),
            json.dumps(risk_tags, ensure_ascii=False),
            json.dumps(keyword_tags, ensure_ascii=False),
            sentiment,
            summary,
            data_quality,
            has_discrepancy,
        ))

        logger.info(f"ğŸ·ï¸ [íƒœê¹…] ì„¸ì…˜ íƒœê¹… ì™„ë£Œ: {session_id} - "
                     f"interest={len(interest_tags)}, risk={len(risk_tags)}, "
                     f"sentiment={sentiment}, quality={data_quality}")
        return tag_data

    except Exception as e:
        logger.warning(f"âš ï¸ [íƒœê¹…] ì„¸ì…˜ íƒœê¹… ì‹¤íŒ¨: {session_id} - {e}")
        return None


async def get_session_tags(session_id: str, partner_id: str) -> Optional[Dict[str, Any]]:
    """ì„¸ì…˜ íƒœê·¸ ì¡°íšŒ"""
    try:
        query = """
            SELECT interest_tags, risk_tags, keyword_tags, sentiment,
                   conversation_summary, data_quality_score, has_discrepancy,
                   created_at, updated_at
            FROM welno.tb_chat_session_tags
            WHERE session_id = %s AND partner_id = %s
        """
        result = await db_manager.execute_one(query, (session_id, partner_id))
        return result
    except Exception as e:
        logger.warning(f"âš ï¸ [íƒœê¹…] íƒœê·¸ ì¡°íšŒ ì‹¤íŒ¨: {session_id} - {e}")
        return None
