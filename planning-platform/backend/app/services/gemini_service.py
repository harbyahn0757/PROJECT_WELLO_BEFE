import os
import json
import logging
import asyncio
from typing import Optional, List, Dict, Any, Union
from dataclasses import dataclass
from datetime import datetime

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

from app.core.config import settings

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)

@dataclass
class GeminiRequest:
    """Gemini API ìš”ì²­ ë°ì´í„° í´ë˜ìŠ¤"""
    prompt: str
    model: str = "gemini-1.5-pro"  # ê¸°ë³¸ ëª¨ë¸
    temperature: float = 0.3
    max_tokens: int = 4096
    response_format: Optional[Dict[str, Any]] = None  # JSON ì‘ë‹µ ìš”ì²­ ì‹œ {"type": "json_object"}
    chat_history: Optional[List[Dict[str, str]]] = None  # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ (role, content)

@dataclass
class GeminiResponse:
    """Gemini API ì‘ë‹µ ë°ì´í„° í´ë˜ìŠ¤"""
    content: Optional[str] = None
    success: bool = False
    error: Optional[str] = None
    usage: Optional[Dict[str, int]] = None

class GeminiService:
    """Google Gemini ì„œë¹„ìŠ¤ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self._api_key: Optional[str] = None
        self._initialized: bool = False
        self._chat_sessions: Dict[str, Any] = {}  # ì„¸ì…˜ë³„ ChatSession ì €ì¥
        
    async def initialize(self):
        """Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
        if self._initialized:
            return

        self._api_key = settings.google_gemini_api_key
        
        if self._api_key and self._api_key != "dev-gemini-key":
            genai.configure(api_key=self._api_key)
            self._initialized = True
            logger.info("âœ… [Gemini Service] ì´ˆê¸°í™” ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ [Gemini Service] API í‚¤ ì—†ìŒ ë˜ëŠ” ìœ íš¨í•˜ì§€ ì•ŠìŒ")
            self._initialized = False
        
    async def call_api(
        self,
        request: GeminiRequest,
        save_log: bool = True,
        patient_uuid: Optional[str] = None,
        session_id: Optional[str] = None,
        step_number: Optional[str] = None,
        step_name: Optional[str] = None
    ) -> GeminiResponse:
        """Gemini API í˜¸ì¶œ"""
        
        if not self._initialized:
            await self.initialize()
            
        if not self._initialized:
            return GeminiResponse(success=False, error="Gemini ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        try:
            # ëª¨ë¸ ì„¤ì •
            generation_config = {
                "temperature": request.temperature,
                "max_output_tokens": request.max_tokens,
            }
            
            # JSON ì‘ë‹µì„ ê°•ì œí•˜ë ¤ë©´ í”„ë¡¬í”„íŠ¸ì— ì§€ì‹œí•˜ê±°ë‚˜ response_mime_type ì„¤ì • (1.5 Proë¶€í„° ì§€ì›)
            if request.response_format and request.response_format.get("type") == "json_object":
                generation_config["response_mime_type"] = "application/json"

            model = genai.GenerativeModel(
                model_name=request.model,
                generation_config=generation_config
            )

            # ì•ˆì „ ì„¤ì • (ì°¨ë‹¨ ìµœì†Œí™”)
            safety_settings = {
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }

            # ë¹„ë™ê¸° í˜¸ì¶œ (asyncio.to_threadë¡œ ë˜í•‘, genai ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ê¸°ë³¸ì ìœ¼ë¡œ ë™ê¸°ì‹ì´ë¯€ë¡œ)
            logger.info(f"ğŸ“¡ [Gemini Service] API í˜¸ì¶œ ì¤‘... (Model: {request.model})")
            
            response = await asyncio.to_thread(
                model.generate_content,
                request.prompt,
                safety_settings=safety_settings
            )
            
            response_text = response.text
            
            # ë¡œê¹… ì €ì¥
            if save_log and patient_uuid:
                from app.services.session_logger import get_session_logger
                session_logger = get_session_logger()
                
                # ë¡œê·¸ì— ì €ì¥í•  ìš”ì²­ ë°ì´í„° êµ¬ì„±
                log_request_data = {
                    "model": request.model,
                    "prompt": request.prompt,
                    "temperature": request.temperature
                }
                
                # ë¡œê·¸ì— ì €ì¥í•  ì‘ë‹µ ë°ì´í„° êµ¬ì„±
                log_response_data = {
                    "content": response_text,
                    "usage": {
                         # GeminiëŠ” ì •í™•í•œ í† í° ì‚¬ìš©ëŸ‰ì„ ì œê³µí•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ (ë©”íƒ€ë°ì´í„° í™•ì¸ í•„ìš”)
                        "prompt_tokens": 0, 
                        "completion_tokens": 0,
                        "total_tokens": 0
                    }
                }
                if response.usage_metadata:
                     log_response_data["usage"] = {
                        "prompt_tokens": response.usage_metadata.prompt_token_count,
                        "completion_tokens": response.usage_metadata.candidates_token_count,
                        "total_tokens": response.usage_metadata.total_token_count
                     }

                session_logger.log_step(
                    patient_uuid=patient_uuid,
                    step_number=step_number or "unknown",
                    step_name=step_name or "Gemini Analysis",
                    request_data=log_request_data,
                    response_data=log_response_data,
                    session_id=session_id
                )

            return GeminiResponse(
                content=response_text,
                success=True,
                usage={
                    "total_tokens": response.usage_metadata.total_token_count if response.usage_metadata else 0
                }
            )

        except Exception as e:
            logger.error(f"âŒ [Gemini Service] API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            return GeminiResponse(success=False, error=str(e))

    async def stream_api(self, request: GeminiRequest, session_id: Optional[str] = None):
        """Gemini API ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (ì„¸ì…˜ íˆìŠ¤í† ë¦¬ ì§€ì›)"""
        if not self._initialized:
            await self.initialize()
            
        if not self._initialized:
            yield "Gemini ì„œë¹„ìŠ¤ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            return

        try:
            generation_config = {
                "temperature": request.temperature,
                "max_output_tokens": request.max_tokens,
            }
            
            model = genai.GenerativeModel(
                model_name=request.model,
                generation_config=generation_config
            )

            safety_settings = {
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }

            logger.info(f"ğŸ“¡ [Gemini Service] ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ ì¤‘... (Model: {request.model}, Session: {session_id})")
            
            # ì„¸ì…˜ íˆìŠ¤í† ë¦¬ê°€ ìˆìœ¼ë©´ ChatSession ì‚¬ìš©
            if session_id and request.chat_history and len(request.chat_history) > 0:
                # ê¸°ì¡´ íˆìŠ¤í† ë¦¬ë¡œ ChatSession ì‹œì‘
                chat_session = model.start_chat(history=request.chat_history)
                # ìƒˆ ë©”ì‹œì§€ ì „ì†¡
                response = chat_session.send_message(
                    request.prompt,
                    safety_settings=safety_settings,
                    stream=True
                )
            else:
                # ì¼ë°˜ ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (ì²« ë©”ì‹œì§€ ë˜ëŠ” íˆìŠ¤í† ë¦¬ ì—†ìŒ)
                response = model.generate_content(
                    request.prompt,
                    safety_settings=safety_settings,
                    stream=True
                )
            
            for chunk in response:
                if chunk.text:
                    yield chunk.text

        except Exception as e:
            logger.error(f"âŒ [Gemini Service] ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
            yield f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
    
    def _format_chat_history(self, history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ Gemini Chat í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        formatted = []
        for msg in history:
            role = msg.get("role", "user")
            content = msg.get("content", "")
            
            if not content:
                continue
            
            # Gemini Chat í˜•ì‹: "user" ë˜ëŠ” "model"
            if role == "assistant":
                role = "model"
            elif role != "user":
                continue  # userì™€ assistantë§Œ ì§€ì›
            
            formatted.append({
                "role": role,
                "parts": [content]  # Gemini Chat API í˜•ì‹: partsëŠ” ë¦¬ìŠ¤íŠ¸
            })
        
        return formatted

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
gemini_service = GeminiService()

